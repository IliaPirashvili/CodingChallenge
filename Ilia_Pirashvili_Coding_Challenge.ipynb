{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b672ae6a-f642-4227-b674-565a0af87e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arff\n",
    "from math import inf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import pointbiserialr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6852677-fd34-4935-aeb9-d5b0310eafa9",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "928a2bed-3d6b-4ff9-83f5-258ffd3c7b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_freq = arff.load('freMTPL2freq.arff')\n",
    "data_sev = arff.load('freMTPL2sev.arff')\n",
    "\n",
    "# Make them pandas databases\n",
    "df_freq = pd.DataFrame(data_freq, columns=[\n",
    "    \"IDpol\", \"ClaimNb\", \"Exposure\", \"Area\", \"VehPower\", \"VehAge\", \"DrivAge\", \"BonusMalus\", \"VehBrand\", \"VehGas\", \"Density\", \"Region\"])\n",
    "df_sev = pd.DataFrame(data_sev, columns=[\"IDpol\", \"ClaimAmount\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fc4bf3-d57d-4aa3-bbbd-166c2dfc77d6",
   "metadata": {},
   "source": [
    "### Deal with categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82f516f5-b98d-4b1c-a5e2-344366ef1caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "obj_columns = df_freq.select_dtypes(include='object').columns\n",
    "encoded_objs = encoder.fit_transform(df_freq[obj_columns])\n",
    "encoded_columns = [f'{col}_{i+1}' for col in obj_columns for i in range(encoded_objs.shape[1])]\n",
    "df_encoded = pd.concat(\n",
    "    [\n",
    "        df_freq.drop(obj_columns, axis=1),\n",
    "        pd.DataFrame(encoded_objs, columns=encoder.get_feature_names_out(obj_columns))\n",
    "    ],\n",
    "    axis=1)\n",
    "# To make sure ' would not create some problems down the line\n",
    "df_encoded.columns = df_encoded.columns.str.replace(\"'\", \"\")\n",
    "\n",
    "## Other attempts included clustering and dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6aa633-4497-40b6-a923-32bcdd830021",
   "metadata": {},
   "source": [
    "### Feature Engeneering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4352b143-fd76-439b-8046-2e6b325d5710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide(df, columns):\n",
    "    return df[columns[0]] / df[columns[1]]\n",
    "\n",
    "def prod(df, columns):\n",
    "    return df[columns].product(axis=1)\n",
    "\n",
    "def merge_columns(df, operation, columns):\n",
    "    new_column_name = \"@\".join(columns)\n",
    "    df[new_column_name] = operation(df, columns)\n",
    "    return df\n",
    "    \n",
    "# Combine VehAge and VehPower\n",
    "df_eng = merge_columns(df_encoded, prod, [\"VehAge\", \"VehPower\"])\n",
    "## Ideally, one should try a few more. I made one to suggest how I would go about in a more invovled project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b084950f-a70e-4648-af3f-d634d2b4af50",
   "metadata": {},
   "source": [
    "### Combining and priming Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "047c7d5e-6126-4f8d-ad6d-9547056b759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the preict values whereevera available. Wherever not, make it into a separate file df_rest.\n",
    "# The ClaimAmount / Exposure will be added to df_rest, as the goal of this project.\n",
    "df_merged_1 = pd.merge(df_eng, df_sev, on=\"IDpol\").drop(\"IDpol\", axis=1)\n",
    "df_rest = df_eng[~df_eng['IDpol'].isin(df_sev['IDpol'])].drop(\"IDpol\", axis=1)\n",
    "\n",
    "# As we are interested in ClaimAmount over time, replace ClaiAmount with this new column.\n",
    "df_merged = merge_columns(df_merged_1, divide, [\"ClaimAmount\", \"Exposure\"])\n",
    "df_merged = df_merged.drop(\"ClaimAmount\", axis = 1)\n",
    "\n",
    "# Our goal is to obtain df_rest[\"ClaimAmount@Exposure\"].\n",
    "# The other columns are there to avaluate our resultant values in this column.\n",
    "# We first populate df_rest with empty columns, as to avoid potential errors later. We will fill in the values over time.\n",
    "df_rest[\"ClaimAmount@Exposure\"] = np.nan\n",
    "df_rest[\"MSE\"] = np.nan\n",
    "df_rest[\"R-Squared\"] = np.nan\n",
    "df_rest[\"Adj.R-Squared\"] = np.nan\n",
    "df_rest[\"F-Statistic\"] = np.nan\n",
    "df_rest[\"p-Value\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9f8f6d-b52f-4244-830f-b73e20cf4478",
   "metadata": {},
   "source": [
    "## Create Model\n",
    "### Define main preparatory functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98f2b59d-e602-4b6b-9173-80263bebc84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove outliers. \n",
    "## Increase 1.5 to remove less.\n",
    "def remove_outliers(df, columns):\n",
    "    for column in columns:\n",
    "        Q1 = df[column].quantile(0.05)\n",
    "        Q3 = df[column].quantile(0.95)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "## This is now mainly usefd for returning \"top_correlations\": the features which the linear model below will use.\n",
    "## It was also used initally by me to examine the dataset, see for corrolations and help determin my course of action.\n",
    "def correlation_analysis(df):\n",
    "    num_cols = [col for col in df.columns if \"_\" not in col]\n",
    "    correlation_matrix = df[num_cols].corr()\n",
    "    top_correlations = correlation_matrix[\"ClaimAmount@Exposure\"].abs().drop(\"ClaimAmount@Exposure\").sort_values(ascending=False).head(7)\n",
    "\n",
    "    ## To visualise the top correlations.\n",
    "    # print(f\"Top Correlations:\")\n",
    "    # print(top_correlations)\n",
    "    # sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "    # plt.show()\n",
    "\n",
    "    ## The columns with _ in the colum are ones coming form OneHotEncoder and are just 0's and 1'.\n",
    "    ## I used Point-Biserial_Correlation to examine their corollation.\n",
    "    \n",
    "    # bin_cols = [col for col in df.columns if \"_\" in col]\n",
    "    # correlations = {}\n",
    "    # for col in bin_cols:\n",
    "    #     correlation, _ = pointbiserialr(df[col], df['ClaimAmount@Exposure'])\n",
    "    #     correlations[col] = correlation\n",
    "\n",
    "    # correlation_df = pd.DataFrame(\n",
    "    #     list(correlations.items()),\n",
    "    #     columns=['Transformed_Column', 'Point-Biserial_Correlation']\n",
    "    # ).sort_values(by=\"Point-Biserial_Correlation\")\n",
    "\n",
    "    # print(correlation_df)\n",
    "\n",
    "    ## Used histograph to show what values ClaimAmount@Exposure generally took. Mainly in the 2000 - 3000 range.\n",
    "    # sns.histplot(df[\"ClaimAmount@Exposure\"], kde=True)\n",
    "    # plt.show()\n",
    "    \n",
    "    return top_correlations.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42374acd-c183-457a-a8e5-dbc3675e842c",
   "metadata": {},
   "source": [
    "### Define main Function (LinearRegression() model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfc6ce25-c82c-4a49-b4af-b219c0eba8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is the main function.\n",
    "\n",
    "## The reason it is defined as a function is because I decided apply the Linear Regression model on smaller subsets.\n",
    "## Applying it all at once gave bad results, even with some attempts at feature engeineering (more than displayed above).\n",
    "## It suggests to me that the data is not linearly distributed. By restricting myself to smaller sets, I am hoping to get a more line-like shape.\n",
    "                                                                ## Basically, every smooth curve \"is a line\" on a small enough interval.\n",
    "## On the smaller datasets, I am training the linear model, giving me many different models.\n",
    "## If the local linear model is worse than the general linear model, the function will choose the general linear model.\n",
    "## This way, one can optimise the code both globally (genral model), as well as locally.\n",
    "\n",
    "# The function takes in a dataframe and a list of its features as input.\n",
    "# The list will come from the previous function correlation_analysis in this script. But one could also generate it in different ways.\n",
    "def train_linear_model(df, top_correlations):\n",
    "    \n",
    "    y = df[[\"ClaimAmount@Exposure\"]]\n",
    "    ## top_corrlations are the features. It is already made sure not to include the ClaimAmount or its derivatives (our predict).\n",
    "    ## But here it is checked again, just to make sure, especially if this list comes form an alternative source. \n",
    "    X = df[[key for key in top_correlations if key != \"ClaimAmount@Exposure\" and key != \"ClaimAmount\"]]\n",
    "\n",
    "    ## This is important for the loop used below. In case this function is called on empty or one element sets, we can not expect to get a line.\n",
    "    ## However, I have set this line at 36, since below it, it is unlikely to give us a statistically meaningful result.\n",
    "    ## Generic solution, bad as it is, is preferable.\n",
    "    if len(X) < 36:\n",
    "        return generic_model\n",
    "    \n",
    "    # Train and evaluate the model:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Use OLS model for better statistical analysis of the resultant model.\n",
    "    ## I have not used this as well as I should have!\n",
    "    ## I am only using the mean_squared_error for automatic evaluation of my model.\n",
    "    ## The R-squared, p-value etc. were only used to be looked at by me, to test progress of my improvements.\n",
    "    ## It should be used in the automatic evaluation as well!\n",
    "    X_train_with_intercept = sm.add_constant(X_train)\n",
    "    OLS_model = sm.OLS(y_train, X_train_with_intercept).fit()\n",
    "    \n",
    "    r_squared = OLS_model.rsquared\n",
    "    adj_r_squared = OLS_model.rsquared_adj\n",
    "    f_statistic = OLS_model.fvalue\n",
    "    f_statistic_prob = OLS_model.f_pvalue\n",
    "    \n",
    "    mse = mean_squared_error(y_pred, y_test, squared=False)\n",
    "\n",
    "    ## Print the extracted statistics. Will be added to the resultant dataset in the main loop, so no need to print them here.\n",
    "    # print(f\"Mean-squared-error: {mse}\")\n",
    "    # print(f\"R-squared: {r_squared}\")\n",
    "    # print(f\"Adj. R-squared: {adj_r_squared}\")\n",
    "    # print(f\"F-statistic: {f_statistic}\")\n",
    "    # print(f\"Prob (F-statistic): {f_statistic_prob}\")\n",
    "    \n",
    "    return [model, mse, r_squared, adj_r_squared, f_statistic, f_statistic_prob]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5537674-0a2a-4515-bea4-fc25153fd5ee",
   "metadata": {},
   "source": [
    "### Create the generic linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff9b4cfb-127a-4101-b472-d30a044446bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here, one should probably try to make more improvements.\n",
    "## It is used as a fallback, if the specific linear models are not as good, or the dataset they try to fit are too small.\n",
    "cols_to_check = [\"ClaimAmount@Exposure\", \"BonusMalus\"]\n",
    "df_gen = remove_outliers(df_merged, cols_to_check).dropna()\n",
    "top_correlations_gen = correlation_analysis(df_gen)\n",
    "# The name generic_model is used in the funciton train_linear_model. If I change it here, I need to change it there....\n",
    "generic_model = train_linear_model(df_gen, top_correlations_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7851f7-5eee-4adc-9735-f5673bd11152",
   "metadata": {},
   "source": [
    "### Define sub-datasets for more specific model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f8e359b-1894-4b7b-91b6-0e07c06697fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## I set it up using a generic script that does it. Can also be done using vim and macros to do big lists.\n",
    "## An entry of the form\n",
    "## [['Exposure', 0, 0.5], ['VehPower', 0, 5], ['Density', 0, 100]]\n",
    "## will split df_merged, the main data set which has the \"solutions\" ClaimAmount@Exposure, as follows: \n",
    "## Every entry such that 0 <= Exposure < 0.5, VehPower <= 0 < 5 and 0 <= Density < 100.\n",
    "## I am keeping strict equality on the right side to avoid double evaluations (it should not cause a problem either way, but still..)\n",
    "\n",
    "## The idea is to use more sensible numbers, preferably from something like decision trees... Ideally, automatically fed into it.\n",
    "## Setting an empty list ensures that everything is populated, at least with the generic script. The following will then overwrite.\n",
    "list_confitions_models = [\n",
    "    [],\n",
    "    [['Exposure', 0, 0.5], ['VehPower', 0, 5], ['Density', 0, 100]],\n",
    "    [['Exposure', 0, 0.5], ['VehPower', 0, 5], ['Density', 100, inf]],\n",
    "    [['Exposure', 0, 0.5], ['VehPower', 5, inf], ['Density', 0, 100]],\n",
    "    [['Exposure', 0, 0.5], ['VehPower', 5, inf], ['Density', 100, inf]],\n",
    "    \n",
    "    [['Exposure', 0.5, 0.75], ['VehPower', 0, 5], ['Density', 0, 100]],\n",
    "    [['Exposure', 0.5, 0.75], ['VehPower', 0, 5], ['Density', 100, inf]],\n",
    "    [['Exposure', 0.5, 0.75], ['VehPower', 5, inf], ['Density', 0, 100]],\n",
    "    [['Exposure', 0.5, 0.75], ['VehPower', 5, inf], ['Density', 100, inf]],\n",
    "    \n",
    "    [['Exposure', 0.75, 0.99], ['VehPower', 0, 5], ['Density', 0, 100]],\n",
    "    [['Exposure', 0.75, 0.99], ['VehPower', 0, 5], ['Density', 100, inf]],\n",
    "    [['Exposure', 0.75, 0.99], ['VehPower', 5, inf], ['Density', 0, 100]],\n",
    "    [['Exposure', 0.75, 0.99], ['VehPower', 5, inf], ['Density', 100, inf]],\n",
    "    \n",
    "    [['Exposure', 0.99, 1.01], ['VehPower', 0, 5], ['Density', 0, 100]],\n",
    "    [['Exposure', 0.99, 1.01], ['VehPower', 0, 5], ['Density', 100, inf]],\n",
    "    [['Exposure', 0.99, 1.01], ['VehPower', 5, inf], ['Density', 0, 100]],\n",
    "    [['Exposure', 0.99, 1.01], ['VehPower', 5, inf], ['Density', 100, inf]],\n",
    "\n",
    "## Some of the entries cause errors. I dealt with a few of them. But at some point, I just commented it out. :)\n",
    "## This is caused from the entry being too small to be effectively evaluated, hence it's fine to leave it out anyway.\n",
    "#    [['Exposure', 1.01, inf], ['VehPower', 0, 5], ['Density', 0, 100]],\n",
    "    [['Exposure', 1.01, inf], ['VehPower', 0, 5], ['Density', 100, inf]],\n",
    "    [['Exposure', 1.01, inf], ['VehPower', 5, inf], ['Density', 0, 100]],\n",
    "    [['Exposure', 1.01, inf], ['VehPower', 5, inf], ['Density', 100, inf]]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f66c7f7-0aaf-4b2d-83de-487da75ade77",
   "metadata": {},
   "source": [
    "## The main Part\n",
    "\n",
    "## The initial evaluation; for-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "735fb6cc-546c-4347-ac07-bcf3b668f3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for conditions in list_confitions_models:\n",
    "    ## I errors come up, see where...\n",
    "    # print(conditions)\n",
    "\n",
    "    ## Need to set up an inital list of booleans, so that I can store my results after each iteration. Was not able to do it with append...\n",
    "    combined_mask = np.ones(len(df_merged), dtype=bool)\n",
    "    for condition in conditions:\n",
    "        condition_mask = np.logical_and(df_merged[condition[0]] >= condition[1], df_merged[condition[0]] < condition[2])\n",
    "        combined_mask = np.logical_and(combined_mask, condition_mask)\n",
    "\n",
    "    ## df_specified becomes our sub-dataset. We will now create a linear model on this, repeating our steps for the generic one.\n",
    "    df_specified = df_merged[combined_mask]\n",
    "    cols_to_check = [\"ClaimAmount@Exposure\", \"BonusMalus\"]\n",
    "    df_rem_outliers = remove_outliers(df_specified, cols_to_check).dropna()\n",
    "    top_correlations = correlation_analysis(df_rem_outliers)\n",
    "    specific_model = train_linear_model(df_rem_outliers, top_correlations)\n",
    "    ## Remember, train_linear_model returns not just the model, but also some evaluations. \n",
    "    model = specific_model[0]\n",
    "\n",
    "    ## Apply the same condition to df_rest, so that we can populate the corresponding rows with ClaimAmount@Exposure and the evaluations.\n",
    "    rest_combined_mask = np.ones(len(df_rest), dtype=bool)\n",
    "    for condition in conditions:\n",
    "        rest_condition_mask = np.logical_and(df_rest[condition[0]] >= condition[1], df_rest[condition[0]] < condition[2])\n",
    "        rest_combined_mask = np.logical_and(rest_combined_mask, rest_condition_mask)\n",
    "\n",
    "    ## Now we will predict the ClaimAmount@Exposure of the appropriate rows.\n",
    "    X = df_rest[rest_combined_mask]\n",
    "\n",
    "    ## If the specific model is worse than the generic one, use generic one.\n",
    "    ## Here, I am only using mean_squared_error as a metric. This is bad! I should also use R-values etc. for a better evaluation.\n",
    "    if specific_model[1] > generic_model[1]:\n",
    "        specific_model = generic_model\n",
    "\n",
    "    ## Not sure why I have to set model again... but it gave me errors, so I set it by hand it was fixed... I am confused...\n",
    "    ## if specific_model = generic_model, surely model = specific_model[0] = generic_model[0] ?? Same with correlations...\n",
    "    if specific_model == generic_model:\n",
    "        model = generic_model[0]\n",
    "        top_correlations = top_correlations_gen\n",
    "    ## If I have zero features or zero entires... nothing to do...\n",
    "    if len(X[[key for key in top_correlations if key != \"ClaimAmount@Exposure\" and key != \"ClaimAmount\"]]) < 1:\n",
    "        continue\n",
    "    \n",
    "    # Predict and add the ClaimAmount@Exposure values (and evaluations) to df_rest.\n",
    "    predicted_values_spec = model.predict(X[[key for key in top_correlations if key != \"ClaimAmount@Exposure\" and key != \"ClaimAmount\"]])\n",
    "    df_rest.loc[rest_combined_mask, \"ClaimAmount@Exposure\"] = predicted_values_spec\n",
    "    df_rest.loc[rest_combined_mask, \"MSE\"] = specific_model[1]\n",
    "    df_rest.loc[rest_combined_mask, \"R-Squared\"] = specific_model[2]\n",
    "    df_rest.loc[rest_combined_mask, \"Adj.R-Squared\"] = specific_model[3]\n",
    "    df_rest.loc[rest_combined_mask, \"F-Statistic\"] = specific_model[4]\n",
    "    df_rest.loc[rest_combined_mask, \"p-Value\"] = specific_model[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d14adf1-3046-4be7-899d-0562e6e300b9",
   "metadata": {},
   "source": [
    "### Evaluate the final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4f686fb-2206-4d16-94d7-4349b191956d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are << 0 >> values missing in the final database\n",
      "The average error is <<  3057.69 >>.\n",
      "The error or the generic model is <<  4509.41 >>.\n"
     ]
    }
   ],
   "source": [
    "## Make sure, everytihng was filled out.\n",
    "num_missing_values = df_rest[\"ClaimAmount@Exposure\"].size - df_rest[\"ClaimAmount@Exposure\"].dropna().size\n",
    "print(f\"There are << {num_missing_values} >> values missing in the final database\")\n",
    "## Need better evaluation...\n",
    "average_error = (df_rest[\"MSE\"].sum()) / df_rest[\"MSE\"].size\n",
    "print(f\"The average error is << {average_error: .2f} >>.\")\n",
    "print(f\"The error or the generic model is << {generic_model[1]: .2f} >>.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2073896-23aa-4aaa-ac1f-4e82a7fc54a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClaimNb</th>\n",
       "      <th>Exposure</th>\n",
       "      <th>VehPower</th>\n",
       "      <th>VehAge</th>\n",
       "      <th>DrivAge</th>\n",
       "      <th>BonusMalus</th>\n",
       "      <th>Density</th>\n",
       "      <th>Area_B</th>\n",
       "      <th>Area_C</th>\n",
       "      <th>Area_D</th>\n",
       "      <th>...</th>\n",
       "      <th>Region_R91</th>\n",
       "      <th>Region_R93</th>\n",
       "      <th>Region_R94</th>\n",
       "      <th>VehAge@VehPower</th>\n",
       "      <th>ClaimAmount@Exposure</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>Adj.R-Squared</th>\n",
       "      <th>F-Statistic</th>\n",
       "      <th>p-Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ClaimNb, Exposure, VehPower, VehAge, DrivAge, BonusMalus, Density, Area_B, Area_C, Area_D, Area_E, Area_F, VehBrand_B10, VehBrand_B11, VehBrand_B12, VehBrand_B13, VehBrand_B14, VehBrand_B2, VehBrand_B3, VehBrand_B4, VehBrand_B5, VehBrand_B6, VehGas_Regular, Region_R21, Region_R22, Region_R23, Region_R24, Region_R25, Region_R26, Region_R31, Region_R41, Region_R42, Region_R43, Region_R52, Region_R53, Region_R54, Region_R72, Region_R73, Region_R74, Region_R82, Region_R83, Region_R91, Region_R93, Region_R94, VehAge@VehPower, ClaimAmount@Exposure, MSE, R-Squared, Adj.R-Squared, F-Statistic, p-Value]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 51 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rest[df_rest[\"R-Squared\"] > 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597d12c6-d5bf-470d-8ffe-353dce7bd604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
